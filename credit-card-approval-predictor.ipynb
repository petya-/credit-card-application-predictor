{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: category_encoders in /usr/local/lib/python2.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python2.7/site-packages (from category_encoders) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python2.7/site-packages (from category_encoders) (0.20.3)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python2.7/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python2.7/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python2.7/site-packages (from category_encoders) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python2.7/site-packages (from category_encoders) (0.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/site-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/site-packages (from pandas>=0.21.1->category_encoders) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the line below if this is the first time you are running the notebook\n",
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-682967da60fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import category_encoders as ce\n",
    "\n",
    "from six.moves import urllib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening\"\n",
    "CREDIT_DATA_URL = DOWNLOAD_ROOT + \"/crx.data\"\n",
    "CREDIT_DATA_PATH = \"datasets/credit-screening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from its origin\n",
    "def fetch_credit_card_data(credit_data_url=CREDIT_DATA_URL, credit_path=CREDIT_DATA_PATH):\n",
    "    if not os.path.isdir(credit_path):\n",
    "        os.makedirs(credit_path)\n",
    "    credit_data_path = os.path.join(credit_path, \"crx.data\")\n",
    "    urllib.request.urlretrieve(credit_data_url, credit_data_path)\n",
    "\n",
    "fetch_credit_card_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file \n",
    "def load_credit_card_data(credit_data_path=CREDIT_DATA_PATH):\n",
    "    csv_path=os.path.join(credit_data_path, \"crx.data\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    col_names = [\"Gender\",\"Age\",\"Debt\",\"Married\",\"BankCustomer\",\"EducationLevel\",\"Ethnicity\",\"YearsEmployed\",\"PriorDefault\",\"Employed\",\"CreditScore\", \"DriversLicense\", \"Citizen\", \"ZipCode\", \"Income\" , \"ApprovalStatus\"]\n",
    "    return pd.read_csv(csv_path, header=None, names=col_names)\n",
    "\n",
    "dataset = load_credit_card_data()\n",
    "dataframe = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace question mark with NaN\n",
    "# replace + and - with 1 and 0\n",
    "dataset = dataset.replace(\"?\", np.nan).replace('+', 1).replace('-', 0)\n",
    "\n",
    "# convert age from object to float\n",
    "dataset = dataset.astype({\"Age\": float})\n",
    "\n",
    "# replace missing numeric values with mean\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "# replace missing object values with the most freequent value\n",
    "for col in dataset:\n",
    "    if dataset[col].dtypes == 'object':\n",
    "        dataset = dataset.fillna(dataset[col].value_counts().index[0])\n",
    "\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ApprovalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountStatus = pd.value_counts(dataset['ApprovalStatus'].values, sort=False)\n",
    "plt.ylabel('Number of applications')\n",
    "plt.title('Approval status')\n",
    "CountStatus.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode for correlation\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in dataset:\n",
    "    if dataset[col].dtypes == 'object':\n",
    "        dataset[col]=le.fit_transform(dataset[col])\n",
    "\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(bins=20, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap\n",
    "def make_corr_heatmap(data):\n",
    "    corr = data.corr()\n",
    "    sns.heatmap(corr, \n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)\n",
    "\n",
    "make_corr_heatmap(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with ApprovalStatus\n",
    "dataset.corr()['ApprovalStatus'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use MAD to check the spread of the observation from the mean. MAD > std because we have outliers like age, income\n",
    "dataset.mad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with the lowest correlation, or columns that do not make sense\n",
    "dataset = dataset.drop(['DriversLicense', 'ZipCode', 'Ethnicity', 'Gender'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n",
    "dataset = ohe.fit_transform(dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the features and labels\n",
    "dataset = dataset.values\n",
    "X,y = dataset[:,0:34] , dataset[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train, validation and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale the training, validation and testing sets\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = MinMaxScaler()\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)\n",
    "rescaledX_val = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the algorithms\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "gnb = GaussianNB()\n",
    "logreg = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forrest\")\n",
    "\n",
    "roc_rfc = cross_val_score(rfc, rescaledX_train, y_train, scoring='roc_auc', cv = 5).mean()\n",
    "f1_rfc = cross_val_score(rfc, rescaledX_train, y_train, scoring='f1', cv = 5).mean()\n",
    "precision_rfc = cross_val_score(rfc, rescaledX_train, y_train, scoring='precision', cv = 5).mean()\n",
    "rec_rfc = cross_val_score(rfc, rescaledX_train, y_train, scoring='recall', cv = 5).mean()\n",
    "acc_rfc = cross_val_score(rfc, rescaledX_train, y_train, scoring='accuracy', cv = 5).mean()\n",
    "\n",
    "y_pred_rfc = cross_val_predict(rfc, rescaledX_train, y_train, cv=5)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_rfc).ravel()\n",
    "\n",
    "#yi_rfc = 2*roc_rfc-1\n",
    "yi_rfc = ((tp/(tp+fn)-(1-(tn/(fp+tn)))))\n",
    "\n",
    "print(\"AUC: \" , roc_rfc)\n",
    "print(\"F1: \" , f1_rfc)\n",
    "print(\"Precission: \" , precision_rfc)\n",
    "print(\"Recall: \" , rec_rfc)\n",
    "print(\"Accuracy: \" , acc_rfc)\n",
    "print(\"Youden's index\", yi_rfc)\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes\")\n",
    "\n",
    "roc_gnb = cross_val_score(gnb, rescaledX_train, y_train, scoring='roc_auc', cv = 5).mean()\n",
    "f1_gnb = cross_val_score(gnb, rescaledX_train, y_train, scoring='f1', cv = 5).mean()\n",
    "precision_gnb = cross_val_score(gnb, rescaledX_train, y_train, scoring='precision', cv = 5).mean()\n",
    "rec_gnb = cross_val_score(gnb, rescaledX_train, y_train, scoring='recall', cv = 5).mean()\n",
    "acc_gnb= cross_val_score(gnb, rescaledX_train, y_train, scoring='accuracy', cv = 5).mean()\n",
    "\n",
    "y_pred_gnb = cross_val_predict(gnb, rescaledX_train, y_train, cv=5)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_train,y_pred_gnb)\n",
    "\n",
    "yi_gnb = 2*roc_gnb-1\n",
    "\n",
    "print(\"AUC\" , roc_gnb)\n",
    "print(\"F1: \" , f1_gnb)\n",
    "print(\"Precission: \" , precision_gnb)\n",
    "print(\"Recall: \" , rec_gnb)\n",
    "print(\"Accuracy: \" , acc_gnb)\n",
    "print(\"Youden's index\", yi_gnb)\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic regression\")\n",
    "\n",
    "roc_logreg = cross_val_score(logreg, rescaledX_train, y_train, scoring='roc_auc', cv = 5).mean()\n",
    "f1_logreg = cross_val_score(logreg, rescaledX_train, y_train, scoring='f1', cv = 5).mean()\n",
    "precision_logreg = cross_val_score(logreg, rescaledX_train, y_train, scoring='precision', cv = 5).mean()\n",
    "rec_logreg = cross_val_score(logreg, rescaledX_train, y_train, scoring='recall', cv = 5).mean()\n",
    "acc_logreg = cross_val_score(logreg, rescaledX_train, y_train, scoring='accuracy', cv = 5).mean()\n",
    "y_pred_logreg = cross_val_predict(logreg, rescaledX_train, y_train, cv=5)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_train, y_pred_logreg)\n",
    "yi_logreg = 2*roc_logreg-1\n",
    "\n",
    "print(\"AUC of Logistic Regression is: \" , roc_logreg)\n",
    "print(\"F1: \" , f1_logreg)\n",
    "print(\"Precission: \" , precision_logreg)\n",
    "print(\"Recall: \" , rec_logreg)\n",
    "print(\"Accuracy: \" , acc_gnb)\n",
    "print(\"Youden's index\", yi_logreg)\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
